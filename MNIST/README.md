Kaggle Simple MNIST NN from scratch (numpy, no TF/Keras)
使用`numpy`来编写一个识别MNIST手写数字的神经网络步骤

1. **数据加载和预处理**：
   - **目的**：为神经网络提供合适的输入数据。
   - 加载MNIST数据集。
   - 归一化数据，使其范围在[0,1]之间。
   - 对标签进行one-hot编码。
2. **初始化网络参数**：
   - **目的**：为神经网络设置初始权重和偏置。
   - 初始化输入层到隐藏层1的权重和偏置。
   - 初始化隐藏层1到隐藏层2的权重和偏置。
   - 初始化隐藏层2到输出层的权重和偏置。
3. **前向传播**：
   - **目的**：计算每一层的输出。
   - 使用激活函数（例如sigmoid或ReLU）处理每一层的输入得到输出。
   - 使用softmax函数将输出转换为概率。
4. **计算损失**：
   - **目的**：衡量模型的预测与实际标签之间的差异。
   - 使用损失函数（例如交叉熵损失）来计算损失。
5. **反向传播**：
   - **目的**：根据损失计算权重和偏置的梯度，并更新它们。
   - 计算输出层的梯度。
   - 计算隐藏层2的梯度。
   - 计算隐藏层1的梯度。
   - 使用学习率来更新所有的权重和偏置。
6. **训练神经网络**：
   - **目的**：使用训练数据反复进行前向传播、损失计算、反向传播和参数更新，从而优化模型的权重和偏置。
   - 选择一个优化算法（例如SGD、Adam）。
   - 确定训练的迭代次数、批次大小等参数。
   - 可选地使用验证集来监控训练过程，并可能进行早停。
7. **评估模型**：
   - **目的**：确定模型在未见过的数据上的性能。
   - 使用测试集来评估模型的准确率。
8. **调优**：
   - **目的**：优化模型的性能。
   - 调整超参数，如学习率、批次大小、激活函数等。
   - 可以考虑使用正则化（如dropout）来防止过拟合。
9. **预测**：
   - **目的**：使用训练好的模型来预测新的手写数字样本。
10. **结果**：
       通过训练后的模型准确率达到86%
11. **数学推导**：

![AI手稿-2](imgs\AI手稿-2.jpg)

![AI手稿-3](imgs\AI手稿-3.jpg)

![AI手稿-4](imgs\AI手稿-4.jpg)

![AI手稿-5](imgs\AI手稿-5.jpg)

![AI手稿-6](imgs\AI手稿-6.jpg)

